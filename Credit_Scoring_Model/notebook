import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_auc_score,
    RocCurveDisplay
)

import warnings
warnings.filterwarnings("ignore")


data_path = r"C:\ml\credit_risk.csv\credit_risk_dataset.csv"

df = pd.read_csv(data_path)
print("Shape of dataset:", df.shape)
print(df.head())


print("\nDataset Info:")
print(df.info())

print("\nMissing values per column:")
print(df.isna().sum())

print("\nTarget value counts (loan_status):")
print(df['loan_status'].value_counts())


target_col = 'loan_status'
X = df.drop(columns=[target_col])
y = df[target_col]

print("\nFeatures shape:", X.shape)
print("Target shape:", y.shape)


numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_features = X.select_dtypes(include=['object', 'bool']).columns.tolist()

print("\nNumeric columns:", numeric_features)
print("Categorical columns:", categorical_features)


numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)


X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=42,
    stratify=y
)

print("\nTrain shape:", X_train.shape)
print("Test shape:", X_test.shape)


models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(
        n_estimators=200,
        random_state=42
    )
}


def evaluate_model(name, model, X_train, X_test, y_train, y_test):
    print("\n" + "="*60)
    print(f"Training model: {name}")
    print("="*60)

    clf = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', model)
    ])

    clf.fit(X_train, y_train)

    y_pred = clf.predict(X_test)
    y_prob = clf.predict_proba(X_test)[:, 1]

    cm = confusion_matrix(y_test, y_pred)
    print("\nConfusion Matrix:")
    print(cm)

    print("\nClassification Report:")
    print(classification_report(y_test, y_pred))

    roc_auc = roc_auc_score(y_test, y_prob)
    print("ROC-AUC Score:", roc_auc)

    RocCurveDisplay.from_predictions(y_test, y_prob)
    plt.title(f"ROC Curve - {name}")
    plt.show()

    return clf, roc_auc

fitted_models = {}
roc_scores = {}

for name, model in models.items():
    clf, roc_auc = evaluate_model(name, model, X_train, X_test, y_train, y_test)
    fitted_models[name] = clf
    roc_scores[name] = roc_auc

print("\n=== ROC-AUC Scores Comparison ===")
for name, score in roc_scores.items():
    print(f"{name}: {score:.4f}")

best_model_name = max(roc_scores, key=roc_scores.get)
print(f"\nBest model based on ROC-AUC: {best_model_name}")


import joblib

best_model = fitted_models[best_model_name]
joblib.dump(best_model, "best_credit_scoring_model.pkl")
print("\nSaved best model as 'best_credit_scoring_model.pkl'")

